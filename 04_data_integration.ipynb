{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8868ace",
   "metadata": {},
   "source": [
    "# hospital data curation project\n",
    "## phase 4: data integration and merging\n",
    "\n",
    "merge cleaned datasets to create comprehensive analytical datasets:\n",
    "- merge patients + visits\n",
    "- integrate diagnoses and medications\n",
    "- handle conflicts and resolve entities\n",
    "- create master dataset for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1828f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# add src directory to python path\n",
    "notebook_dir = Path(os.getcwd())\n",
    "src_dir = notebook_dir / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import project modules\n",
    "import config\n",
    "import utils\n",
    "\n",
    "# use imported modules\n",
    "CLEANED_DATA_DIR = config.CLEANED_DATA_DIR\n",
    "PREPROCESSED_DATA_DIR = config.PREPROCESSED_DATA_DIR\n",
    "LOGS_DIR = config.LOGS_DIR\n",
    "setup_logging = utils.setup_logging\n",
    "print_section_header = utils.print_section_header\n",
    "save_dataframe = utils.save_dataframe\n",
    "load_dataframe = utils.load_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a939a816",
   "metadata": {},
   "source": [
    "## 1. load cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ce80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 17:48:27,913 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_patients.csv: 3000 rows, 7 columns\n",
      "2025-11-10 17:48:27,958 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_visits.csv: 2481 rows, 8 columns\n",
      "2025-11-10 17:48:27,958 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_visits.csv: 2481 rows, 8 columns\n",
      "2025-11-10 17:48:27,995 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_diagnoses.csv: 7998 rows, 5 columns\n",
      "2025-11-10 17:48:27,995 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_diagnoses.csv: 7998 rows, 5 columns\n",
      "2025-11-10 17:48:28,028 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_medications.csv: 5324 rows, 6 columns\n",
      "2025-11-10 17:48:28,028 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_medications.csv: 5324 rows, 6 columns\n",
      "2025-11-10 17:48:28,063 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_staff.csv: 500 rows, 5 columns\n",
      "2025-11-10 17:48:28,063 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\cleaned\\clean_staff.csv: 500 rows, 5 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            loading cleaned datasets                            \n",
      "================================================================================\n",
      "\n",
      "\n",
      "datasets loaded successfully:\n",
      "  patients: 3000 rows\n",
      "  visits: 2481 rows\n",
      "  diagnoses: 7998 rows\n",
      "  medications: 5324 rows\n",
      "  staff: 500 rows\n",
      "\n",
      "datasets loaded successfully:\n",
      "  patients: 3000 rows\n",
      "  visits: 2481 rows\n",
      "  diagnoses: 7998 rows\n",
      "  medications: 5324 rows\n",
      "  staff: 500 rows\n"
     ]
    }
   ],
   "source": [
    "# setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "# load all cleaned datasets\n",
    "print_section_header(\"loading cleaned datasets\")\n",
    "\n",
    "patients_df = load_dataframe(CLEANED_DATA_DIR / 'clean_patients.csv')\n",
    "visits_df = load_dataframe(CLEANED_DATA_DIR / 'clean_visits.csv')\n",
    "diagnoses_df = load_dataframe(CLEANED_DATA_DIR / 'clean_diagnoses.csv')\n",
    "medications_df = load_dataframe(CLEANED_DATA_DIR / 'clean_medications.csv')\n",
    "staff_df = load_dataframe(CLEANED_DATA_DIR / 'clean_staff.csv')\n",
    "\n",
    "print(\"\\ndatasets loaded successfully:\")\n",
    "print(f\"  patients: {len(patients_df)} rows\")\n",
    "print(f\"  visits: {len(visits_df)} rows\")\n",
    "print(f\"  diagnoses: {len(diagnoses_df)} rows\")\n",
    "print(f\"  medications: {len(medications_df)} rows\")\n",
    "print(f\"  staff: {len(staff_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08edaf18",
   "metadata": {},
   "source": [
    "## 2. merge patients and visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903e24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          merging patients and visits                           \n",
      "================================================================================\n",
      "\n",
      "checking referential integrity...\n",
      "  orphaned visits (no matching patient): 0\n",
      "\n",
      "merged patient-visits dataset: 2481 rows\n",
      "columns: 14\n",
      "\n",
      "sample merged data:\n",
      "  patient_id              name         dob   gender contact_number  \\\n",
      "0     P10003      Susan Wagner  1965-03-01  Unknown  (372)730-3040   \n",
      "1     P10005  Theodore Mcgrath  2009-12-26     Male   321.659.7442   \n",
      "2     P10005  Theodore Mcgrath  2009-12-26     Male   321.659.7442   \n",
      "\n",
      "                               email  \\\n",
      "0  nicolehernandez@banks-higgins.net   \n",
      "1               kmorales@hotmail.com   \n",
      "2               kmorales@hotmail.com   \n",
      "\n",
      "                                            address visit_id admission_date  \\\n",
      "0  4207 Mora Centers Suite 151, Lake Paul, WI 58477   V22056     2024-02-17   \n",
      "1   122 Taylor Station, South Jeffreyfurt, DE 96964   V20238     2024-06-22   \n",
      "2   122 Taylor Station, South Jeffreyfurt, DE 96964   V21235     2024-07-15   \n",
      "\n",
      "  discharge_date admission_type hospital_unit_id attending_physician_id  \\\n",
      "0     2024-08-08      Emergency              U16                   S336   \n",
      "1     2024-07-31       Transfer               U8                   S252   \n",
      "2     2025-06-17        Walk-in               U3                   S277   \n",
      "\n",
      "   length_of_stay  \n",
      "0             173  \n",
      "1              39  \n",
      "2             337  \n"
     ]
    }
   ],
   "source": [
    "# merge patients with visits data\n",
    "print_section_header(\"merging patients and visits\")\n",
    "\n",
    "# check for patient_id consistency\n",
    "print(\"checking referential integrity...\")\n",
    "orphaned_visits = ~visits_df['patient_id'].isin(patients_df['patient_id'])\n",
    "print(f\"  orphaned visits (no matching patient): {orphaned_visits.sum()}\")\n",
    "\n",
    "if orphaned_visits.sum() > 0:\n",
    "    print(f\"  removing {orphaned_visits.sum()} orphaned visits\")\n",
    "    visits_df = visits_df[~orphaned_visits]\n",
    "\n",
    "# merge patients and visits\n",
    "patient_visits = pd.merge(\n",
    "    patients_df,\n",
    "    visits_df,\n",
    "    on='patient_id',\n",
    "    how='inner',\n",
    "    suffixes=('_patient', '_visit')\n",
    ")\n",
    "\n",
    "print(f\"\\nmerged patient-visits dataset: {len(patient_visits)} rows\")\n",
    "print(f\"columns: {len(patient_visits.columns)}\")\n",
    "\n",
    "# display sample\n",
    "print(\"\\nsample merged data:\")\n",
    "print(patient_visits.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693282f1",
   "metadata": {},
   "source": [
    "## 3. aggregate diagnoses per visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6bbb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                             aggregating diagnoses                              \n",
      "================================================================================\n",
      "\n",
      "diagnosis aggregations created:\n",
      "  visits with diagnoses: 3977\n",
      "  average diagnoses per visit: 2.01\n",
      "diagnosis aggregations created:\n",
      "  visits with diagnoses: 3977\n",
      "  average diagnoses per visit: 2.01\n"
     ]
    }
   ],
   "source": [
    "# aggregate diagnoses information\n",
    "print_section_header(\"aggregating diagnoses\")\n",
    "\n",
    "# count diagnoses per visit\n",
    "diagnoses_count = diagnoses_df.groupby('visit_id').size().reset_index(name='diagnosis_count')\n",
    "\n",
    "# get primary diagnosis (first one per visit)\n",
    "primary_diagnosis = diagnoses_df.groupby('visit_id').first().reset_index()\n",
    "primary_diagnosis = primary_diagnosis[['visit_id', 'icd_code']]\n",
    "primary_diagnosis.rename(columns={'icd_code': 'primary_diagnosis'}, inplace=True)\n",
    "\n",
    "# get all diagnosis codes as comma-separated list\n",
    "all_diagnoses = diagnoses_df.groupby('visit_id')['icd_code'].apply(\n",
    "    lambda x: ', '.join(x.astype(str))\n",
    ").reset_index()\n",
    "all_diagnoses.rename(columns={'icd_code': 'all_diagnoses'}, inplace=True)\n",
    "\n",
    "print(f\"diagnosis aggregations created:\")\n",
    "print(f\"  visits with diagnoses: {len(diagnoses_count)}\")\n",
    "print(f\"  average diagnoses per visit: {diagnoses_count['diagnosis_count'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd532827",
   "metadata": {},
   "source": [
    "## 4. aggregate medications per visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d9928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            aggregating medications                             \n",
      "================================================================================\n",
      "\n",
      "medication aggregations created:\n",
      "  visits with medications: 3470\n",
      "  average medications per visit: 1.53\n",
      "medication aggregations created:\n",
      "  visits with medications: 3470\n",
      "  average medications per visit: 1.53\n"
     ]
    }
   ],
   "source": [
    "# aggregate medications information\n",
    "print_section_header(\"aggregating medications\")\n",
    "\n",
    "# count medications per visit\n",
    "medications_count = medications_df.groupby('visit_id').size().reset_index(name='medication_count')\n",
    "\n",
    "# get all medications as comma-separated list\n",
    "all_medications = medications_df.groupby('visit_id')['medication_name'].apply(\n",
    "    lambda x: ', '.join(x.astype(str))\n",
    ").reset_index()\n",
    "all_medications.rename(columns={'medication_name': 'all_medications'}, inplace=True)\n",
    "\n",
    "print(f\"medication aggregations created:\")\n",
    "print(f\"  visits with medications: {len(medications_count)}\")\n",
    "print(f\"  average medications per visit: {medications_count['medication_count'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785c541",
   "metadata": {},
   "source": [
    "## 5. create comprehensive master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055e5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            creating master dataset                             \n",
      "================================================================================\n",
      "\n",
      "starting with patient-visits: 2481 rows\n",
      "after merging diagnosis count: 2481 rows\n",
      "after merging primary diagnosis: 2481 rows\n",
      "after merging all diagnoses: 2481 rows\n",
      "after merging medication count: 2481 rows\n",
      "after merging all medications: 2481 rows\n",
      "\n",
      "final master dataset:\n",
      "  rows: 2481\n",
      "  columns: 19\n"
     ]
    }
   ],
   "source": [
    "# merge all components into master dataset\n",
    "print_section_header(\"creating master dataset\")\n",
    "\n",
    "# start with patient_visits\n",
    "master_df = patient_visits.copy()\n",
    "print(f\"starting with patient-visits: {len(master_df)} rows\")\n",
    "\n",
    "# merge diagnosis count\n",
    "master_df = pd.merge(\n",
    "    master_df,\n",
    "    diagnoses_count,\n",
    "    on='visit_id',\n",
    "    how='left'\n",
    ")\n",
    "master_df['diagnosis_count'].fillna(0, inplace=True)\n",
    "print(f\"after merging diagnosis count: {len(master_df)} rows\")\n",
    "\n",
    "# merge primary diagnosis\n",
    "master_df = pd.merge(\n",
    "    master_df,\n",
    "    primary_diagnosis,\n",
    "    on='visit_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"after merging primary diagnosis: {len(master_df)} rows\")\n",
    "\n",
    "# merge all diagnoses\n",
    "master_df = pd.merge(\n",
    "    master_df,\n",
    "    all_diagnoses,\n",
    "    on='visit_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"after merging all diagnoses: {len(master_df)} rows\")\n",
    "\n",
    "# merge medication count\n",
    "master_df = pd.merge(\n",
    "    master_df,\n",
    "    medications_count,\n",
    "    on='visit_id',\n",
    "    how='left'\n",
    ")\n",
    "master_df['medication_count'].fillna(0, inplace=True)\n",
    "print(f\"after merging medication count: {len(master_df)} rows\")\n",
    "\n",
    "# merge all medications\n",
    "master_df = pd.merge(\n",
    "    master_df,\n",
    "    all_medications,\n",
    "    on='visit_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"after merging all medications: {len(master_df)} rows\")\n",
    "\n",
    "print(f\"\\nfinal master dataset:\")\n",
    "print(f\"  rows: {len(master_df)}\")\n",
    "print(f\"  columns: {len(master_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d8e41",
   "metadata": {},
   "source": [
    "## 6. merge staff information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1385b080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           merging staff information                            \n",
      "================================================================================\n",
      "\n",
      "staff information merged: 2481 rows\n"
     ]
    }
   ],
   "source": [
    "# merge staff information if available\n",
    "print_section_header(\"merging staff information\")\n",
    "\n",
    "if 'attending_physician_id' in master_df.columns or 'staff_id' in visits_df.columns:\n",
    "    # determine the join column\n",
    "    join_col = 'attending_physician_id' if 'attending_physician_id' in master_df.columns else 'staff_id'\n",
    "    \n",
    "    if join_col in master_df.columns and 'staff_id' in staff_df.columns:\n",
    "        master_df = pd.merge(\n",
    "            master_df,\n",
    "            staff_df,\n",
    "            left_on=join_col,\n",
    "            right_on='staff_id',\n",
    "            how='left',\n",
    "            suffixes=('', '_staff')\n",
    "        )\n",
    "        print(f\"staff information merged: {len(master_df)} rows\")\n",
    "    else:\n",
    "        print(\"staff information columns not found for merging\")\n",
    "else:\n",
    "    print(\"no staff id column available in visits data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677da574",
   "metadata": {},
   "source": [
    "## 7. handle missing values in merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a2c1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                   handling missing values in master dataset                    \n",
      "================================================================================\n",
      "\n",
      "columns with missing values:\n",
      "  all_medications: 750 (30.23%)\n",
      "  primary_diagnosis: 480 (19.35%)\n",
      "  all_diagnoses: 480 (19.35%)\n",
      "\n",
      "missing values after handling: 1710\n"
     ]
    }
   ],
   "source": [
    "# handle missing values in merged dataset\n",
    "print_section_header(\"handling missing values in master dataset\")\n",
    "\n",
    "# display missing values\n",
    "missing_summary = master_df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"columns with missing values:\")\n",
    "for col, count in missing_summary.items():\n",
    "    pct = (count / len(master_df)) * 100\n",
    "    print(f\"  {col}: {count} ({pct:.2f}%)\")\n",
    "\n",
    "# fill specific missing values\n",
    "if 'diagnosis_count' in master_df.columns:\n",
    "    master_df['diagnosis_count'].fillna(0, inplace=True)\n",
    "\n",
    "if 'medication_count' in master_df.columns:\n",
    "    master_df['medication_count'].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"\\nmissing values after handling: {master_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9eef1",
   "metadata": {},
   "source": [
    "## 8. save integrated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33809e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 17:48:28,915 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\master_patient_visits.csv\n",
      "2025-11-10 17:48:28,930 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\curated_diagnoses.csv\n",
      "2025-11-10 17:48:28,947 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\curated_medications.csv\n",
      "2025-11-10 17:48:28,930 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\curated_diagnoses.csv\n",
      "2025-11-10 17:48:28,947 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\curated_medications.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           saving integrated datasets                           \n",
      "================================================================================\n",
      "\n",
      "✓ master dataset saved: 2481 rows, 24 columns\n",
      "✓ curated diagnoses saved: 7998 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 17:48:28,947 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\curated_staff.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ curated medications saved: 5324 rows\n",
      "✓ curated staff saved: 500 rows\n"
     ]
    }
   ],
   "source": [
    "# save master dataset and separate entity tables\n",
    "print_section_header(\"saving integrated datasets\")\n",
    "\n",
    "# save master dataset\n",
    "save_dataframe(master_df, PREPROCESSED_DATA_DIR / 'master_patient_visits.csv')\n",
    "print(f\"✓ master dataset saved: {len(master_df)} rows, {len(master_df.columns)} columns\")\n",
    "\n",
    "# save curated entity tables\n",
    "save_dataframe(diagnoses_df, PREPROCESSED_DATA_DIR / 'curated_diagnoses.csv')\n",
    "print(f\"✓ curated diagnoses saved: {len(diagnoses_df)} rows\")\n",
    "\n",
    "save_dataframe(medications_df, PREPROCESSED_DATA_DIR / 'curated_medications.csv')\n",
    "print(f\"✓ curated medications saved: {len(medications_df)} rows\")\n",
    "\n",
    "save_dataframe(staff_df, PREPROCESSED_DATA_DIR / 'curated_staff.csv')\n",
    "print(f\"✓ curated staff saved: {len(staff_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567412b",
   "metadata": {},
   "source": [
    "## 9. generate integration report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ecdef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           integration summary report                           \n",
      "================================================================================\n",
      "\n",
      "\n",
      "source datasets:\n",
      "  patients: 3000 rows\n",
      "  visits: 2481 rows\n",
      "  diagnoses: 7998 rows\n",
      "  medications: 5324 rows\n",
      "  staff: 500 rows\n",
      "\n",
      "master dataset:\n",
      "  total_rows: 2481\n",
      "  total_columns: 24\n",
      "  unique_patients: 1692\n",
      "  unique_visits: 2481\n",
      "  missing_values: 1710\n",
      "\n",
      "master dataset columns:\n",
      "  1. patient_id\n",
      "  2. name\n",
      "  3. dob\n",
      "  4. gender\n",
      "  5. contact_number\n",
      "  6. email\n",
      "  7. address\n",
      "  8. visit_id\n",
      "  9. admission_date\n",
      "  10. discharge_date\n",
      "  11. admission_type\n",
      "  12. hospital_unit_id\n",
      "  13. attending_physician_id\n",
      "  14. length_of_stay\n",
      "  15. diagnosis_count\n",
      "  16. primary_diagnosis\n",
      "  17. all_diagnoses\n",
      "  18. medication_count\n",
      "  19. all_medications\n",
      "  20. staff_id\n",
      "  21. name_staff\n",
      "  22. designation\n",
      "  23. unit_id\n",
      "  24. joining_date\n"
     ]
    }
   ],
   "source": [
    "# create integration report\n",
    "print_section_header(\"integration summary report\")\n",
    "\n",
    "integration_report = {\n",
    "    'source_datasets': {\n",
    "        'patients': len(patients_df),\n",
    "        'visits': len(visits_df),\n",
    "        'diagnoses': len(diagnoses_df),\n",
    "        'medications': len(medications_df),\n",
    "        'staff': len(staff_df)\n",
    "    },\n",
    "    'master_dataset': {\n",
    "        'total_rows': len(master_df),\n",
    "        'total_columns': len(master_df.columns),\n",
    "        'unique_patients': master_df['patient_id'].nunique() if 'patient_id' in master_df.columns else 0,\n",
    "        'unique_visits': master_df['visit_id'].nunique() if 'visit_id' in master_df.columns else 0,\n",
    "        'missing_values': master_df.isnull().sum().sum()\n",
    "    }\n",
    "}\n",
    "\n",
    "# display report\n",
    "print(\"\\nsource datasets:\")\n",
    "for dataset, count in integration_report['source_datasets'].items():\n",
    "    print(f\"  {dataset}: {count} rows\")\n",
    "\n",
    "print(\"\\nmaster dataset:\")\n",
    "for metric, value in integration_report['master_dataset'].items():\n",
    "    print(f\"  {metric}: {value}\")\n",
    "\n",
    "# display column list\n",
    "print(\"\\nmaster dataset columns:\")\n",
    "for i, col in enumerate(master_df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24d059",
   "metadata": {},
   "source": [
    "## summary\n",
    "\n",
    "data integration completed:\n",
    "- ✓ patients and visits merged successfully\n",
    "- ✓ diagnoses aggregated per visit\n",
    "- ✓ medications aggregated per visit\n",
    "- ✓ staff information integrated\n",
    "- ✓ master dataset created with all entities\n",
    "- ✓ all integrated datasets saved to `data/preprocessed/`\n",
    "\n",
    "next phase: data transformation and feature engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
