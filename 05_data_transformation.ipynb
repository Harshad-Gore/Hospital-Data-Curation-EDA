{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077e2578",
   "metadata": {},
   "source": [
    "# hospital data curation project\n",
    "## phase 5: data transformation and feature engineering\n",
    "\n",
    "create analytical features:\n",
    "- derive length of stay and readmission flags\n",
    "- create age groups and categorical buckets\n",
    "- one-hot encode categorical variables\n",
    "- engineer features for predictive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0230cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# add src directory to python path\n",
    "notebook_dir = Path(os.getcwd())\n",
    "src_dir = notebook_dir / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import project modules\n",
    "import config\n",
    "import utils\n",
    "\n",
    "# use imported modules\n",
    "PREPROCESSED_DATA_DIR = config.PREPROCESSED_DATA_DIR\n",
    "READMISSION_THRESHOLD_DAYS = config.READMISSION_THRESHOLD_DAYS\n",
    "AGE_GROUPS = config.AGE_GROUPS\n",
    "setup_logging = utils.setup_logging\n",
    "print_section_header = utils.print_section_header\n",
    "save_dataframe = utils.save_dataframe\n",
    "load_dataframe = utils.load_dataframe\n",
    "create_age_groups = utils.create_age_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0430b21",
   "metadata": {},
   "source": [
    "## 1. load preprocessed master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f71e811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 17:48:49,103 - root - INFO - loaded dataframe from d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\master_patient_visits.csv: 2481 rows, 24 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                             loading master dataset                             \n",
      "================================================================================\n",
      "\n",
      "master dataset loaded:\n",
      "  rows: 2481\n",
      "  columns: 24\n",
      "\n",
      "initial columns: ['patient_id', 'name', 'dob', 'gender', 'contact_number', 'email', 'address', 'visit_id', 'admission_date', 'discharge_date', 'admission_type', 'hospital_unit_id', 'attending_physician_id', 'length_of_stay', 'diagnosis_count', 'primary_diagnosis', 'all_diagnoses', 'medication_count', 'all_medications', 'staff_id', 'name_staff', 'designation', 'unit_id', 'joining_date']\n"
     ]
    }
   ],
   "source": [
    "# setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "# load master dataset\n",
    "print_section_header(\"loading master dataset\")\n",
    "\n",
    "master_df = load_dataframe(PREPROCESSED_DATA_DIR / 'master_patient_visits.csv')\n",
    "\n",
    "print(f\"master dataset loaded:\")\n",
    "print(f\"  rows: {len(master_df)}\")\n",
    "print(f\"  columns: {len(master_df.columns)}\")\n",
    "print(f\"\\ninitial columns: {list(master_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ec182",
   "metadata": {},
   "source": [
    "## 2. derive length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bee1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            deriving length of stay                             \n",
      "================================================================================\n",
      "\n",
      "length of stay statistics:\n",
      "  mean: 182.27 days\n",
      "  median: 180.00 days\n",
      "  std: 105.07 days\n",
      "  min: 0 days\n",
      "  max: 365 days\n"
     ]
    }
   ],
   "source": [
    "# calculate length of stay if not already present\n",
    "print_section_header(\"deriving length of stay\")\n",
    "\n",
    "if 'admission_date' in master_df.columns and 'discharge_date' in master_df.columns:\n",
    "    # ensure dates are in datetime format\n",
    "    master_df['admission_date'] = pd.to_datetime(master_df['admission_date'], errors='coerce')\n",
    "    master_df['discharge_date'] = pd.to_datetime(master_df['discharge_date'], errors='coerce')\n",
    "    \n",
    "    # calculate los if not present\n",
    "    if 'length_of_stay' not in master_df.columns:\n",
    "        master_df['length_of_stay'] = (master_df['discharge_date'] - master_df['admission_date']).dt.days\n",
    "    \n",
    "    print(\"length of stay statistics:\")\n",
    "    print(f\"  mean: {master_df['length_of_stay'].mean():.2f} days\")\n",
    "    print(f\"  median: {master_df['length_of_stay'].median():.2f} days\")\n",
    "    print(f\"  std: {master_df['length_of_stay'].std():.2f} days\")\n",
    "    print(f\"  min: {master_df['length_of_stay'].min()} days\")\n",
    "    print(f\"  max: {master_df['length_of_stay'].max()} days\")\n",
    "else:\n",
    "    print(\"date columns not found for los calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdb820",
   "metadata": {},
   "source": [
    "## 3. identify readmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b177c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            identifying readmissions                            \n",
      "================================================================================\n",
      "\n",
      "readmission analysis (within 30 days):\n",
      "  total readmissions: 117\n",
      "  readmission rate: 4.72%\n",
      "  unique patients with readmissions: 108\n"
     ]
    }
   ],
   "source": [
    "# identify readmissions within threshold period\n",
    "print_section_header(\"identifying readmissions\")\n",
    "\n",
    "if 'patient_id' in master_df.columns and 'admission_date' in master_df.columns:\n",
    "    # sort by patient and admission date\n",
    "    master_df = master_df.sort_values(['patient_id', 'admission_date'])\n",
    "    \n",
    "    # calculate days since last admission for same patient\n",
    "    master_df['days_since_last_admission'] = master_df.groupby('patient_id')['admission_date'].diff().dt.days\n",
    "    \n",
    "    # flag readmissions (within threshold days)\n",
    "    master_df['is_readmitted'] = (\n",
    "        (master_df['days_since_last_admission'] <= READMISSION_THRESHOLD_DAYS) & \n",
    "        (master_df['days_since_last_admission'].notna())\n",
    "    ).astype(int)\n",
    "    \n",
    "    readmission_count = master_df['is_readmitted'].sum()\n",
    "    readmission_rate = (readmission_count / len(master_df)) * 100\n",
    "    \n",
    "    print(f\"readmission analysis (within {READMISSION_THRESHOLD_DAYS} days):\")\n",
    "    print(f\"  total readmissions: {readmission_count}\")\n",
    "    print(f\"  readmission rate: {readmission_rate:.2f}%\")\n",
    "    print(f\"  unique patients with readmissions: {master_df[master_df['is_readmitted']==1]['patient_id'].nunique()}\")\n",
    "else:\n",
    "    print(\"required columns not found for readmission analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977cc2c0",
   "metadata": {},
   "source": [
    "## 4. create age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946289a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                              creating age groups                               \n",
      "================================================================================\n",
      "\n",
      "age column not found\n"
     ]
    }
   ],
   "source": [
    "# create age group categories\n",
    "print_section_header(\"creating age groups\")\n",
    "\n",
    "if 'age' in master_df.columns:\n",
    "    master_df['age_group'] = create_age_groups(master_df['age'], AGE_GROUPS)\n",
    "    \n",
    "    print(\"age group distribution:\")\n",
    "    age_dist = master_df['age_group'].value_counts().sort_index()\n",
    "    for group, count in age_dist.items():\n",
    "        pct = (count / len(master_df)) * 100\n",
    "        print(f\"  {group}: {count} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"age column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19205a",
   "metadata": {},
   "source": [
    "## 5. create length of stay categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b5375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          categorizing length of stay                           \n",
      "================================================================================\n",
      "\n",
      "length of stay category distribution:\n",
      "  extended_stay: 2387 (96.21%)\n",
      "  long_stay: 45 (1.81%)\n",
      "  medium_stay: 40 (1.61%)\n",
      "  short_stay: 9 (0.36%)\n"
     ]
    }
   ],
   "source": [
    "# categorize length of stay\n",
    "print_section_header(\"categorizing length of stay\")\n",
    "\n",
    "if 'length_of_stay' in master_df.columns:\n",
    "    # create los categories\n",
    "    def categorize_los(days):\n",
    "        if days <= 1:\n",
    "            return 'short_stay'\n",
    "        elif days <= 7:\n",
    "            return 'medium_stay'\n",
    "        elif days <= 14:\n",
    "            return 'long_stay'\n",
    "        else:\n",
    "            return 'extended_stay'\n",
    "    \n",
    "    master_df['los_category'] = master_df['length_of_stay'].apply(categorize_los)\n",
    "    \n",
    "    print(\"length of stay category distribution:\")\n",
    "    los_dist = master_df['los_category'].value_counts()\n",
    "    for category, count in los_dist.items():\n",
    "        pct = (count / len(master_df)) * 100\n",
    "        print(f\"  {category}: {count} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278701c",
   "metadata": {},
   "source": [
    "## 6. create high-risk patient flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8fc6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         identifying high-risk patients                         \n",
      "================================================================================\n",
      "\n",
      "patients with 3+ diagnoses: 555\n",
      "patients with los > 10 days: 2413\n",
      "patients with 5+ medications: 0\n",
      "\n",
      "total high-risk patients: 544 (21.93%)\n"
     ]
    }
   ],
   "source": [
    "# identify high-risk patients based on multiple criteria\n",
    "print_section_header(\"identifying high-risk patients\")\n",
    "\n",
    "# define high-risk criteria\n",
    "risk_factors = []\n",
    "\n",
    "# factor 1: multiple diagnoses\n",
    "if 'diagnosis_count' in master_df.columns:\n",
    "    high_diagnosis = master_df['diagnosis_count'] >= 3\n",
    "    risk_factors.append(high_diagnosis)\n",
    "    print(f\"patients with 3+ diagnoses: {high_diagnosis.sum()}\")\n",
    "\n",
    "# factor 2: long length of stay\n",
    "if 'length_of_stay' in master_df.columns:\n",
    "    long_stay = master_df['length_of_stay'] > 10\n",
    "    risk_factors.append(long_stay)\n",
    "    print(f\"patients with los > 10 days: {long_stay.sum()}\")\n",
    "\n",
    "# factor 3: multiple medications\n",
    "if 'medication_count' in master_df.columns:\n",
    "    high_meds = master_df['medication_count'] >= 5\n",
    "    risk_factors.append(high_meds)\n",
    "    print(f\"patients with 5+ medications: {high_meds.sum()}\")\n",
    "\n",
    "# factor 4: elderly patients\n",
    "if 'age' in master_df.columns:\n",
    "    elderly = master_df['age'] >= 65\n",
    "    risk_factors.append(elderly)\n",
    "    print(f\"patients aged 65+: {elderly.sum()}\")\n",
    "\n",
    "# combine risk factors (at least 2 factors present)\n",
    "if len(risk_factors) > 0:\n",
    "    risk_score = sum(risk_factors)\n",
    "    master_df['is_high_risk'] = (risk_score >= 2).astype(int)\n",
    "    \n",
    "    high_risk_count = master_df['is_high_risk'].sum()\n",
    "    high_risk_rate = (high_risk_count / len(master_df)) * 100\n",
    "    \n",
    "    print(f\"\\ntotal high-risk patients: {high_risk_count} ({high_risk_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cac43",
   "metadata": {},
   "source": [
    "## 7. one-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8443dd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                     one-hot encoding categorical variables                     \n",
      "================================================================================\n",
      "\n",
      "encoding columns: ['gender', 'los_category', 'admission_type']\n",
      "  gender: created 4 dummy variables\n",
      "  los_category: created 4 dummy variables\n",
      "  admission_type: created 4 dummy variables\n",
      "\n",
      "total columns after encoding: 40\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode categorical variables for modeling\n",
    "print_section_header(\"one-hot encoding categorical variables\")\n",
    "\n",
    "# identify categorical columns to encode\n",
    "categorical_columns = []\n",
    "\n",
    "if 'gender' in master_df.columns:\n",
    "    categorical_columns.append('gender')\n",
    "\n",
    "if 'age_group' in master_df.columns:\n",
    "    categorical_columns.append('age_group')\n",
    "\n",
    "if 'los_category' in master_df.columns:\n",
    "    categorical_columns.append('los_category')\n",
    "\n",
    "if 'admission_type' in master_df.columns:\n",
    "    categorical_columns.append('admission_type')\n",
    "\n",
    "print(f\"encoding columns: {categorical_columns}\")\n",
    "\n",
    "# create encoded dataframe\n",
    "encoded_df = master_df.copy()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in encoded_df.columns:\n",
    "        # create dummy variables\n",
    "        dummies = pd.get_dummies(encoded_df[col], prefix=col, drop_first=False)\n",
    "        encoded_df = pd.concat([encoded_df, dummies], axis=1)\n",
    "        print(f\"  {col}: created {len(dummies.columns)} dummy variables\")\n",
    "\n",
    "print(f\"\\ntotal columns after encoding: {len(encoded_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf846c",
   "metadata": {},
   "source": [
    "## 8. normalize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a0fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          creating normalized features                          \n",
      "================================================================================\n",
      "\n",
      "numerical features to normalize: ['length_of_stay', 'diagnosis_count', 'medication_count']\n",
      "  length_of_stay_normalized created\n",
      "  diagnosis_count_normalized created\n",
      "  medication_count_normalized created\n",
      "numerical features to normalize: ['length_of_stay', 'diagnosis_count', 'medication_count']\n",
      "  length_of_stay_normalized created\n",
      "  diagnosis_count_normalized created\n",
      "  medication_count_normalized created\n"
     ]
    }
   ],
   "source": [
    "# normalize numerical features for modeling\n",
    "print_section_header(\"creating normalized features\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_features = []\n",
    "\n",
    "# identify numerical columns\n",
    "for col in ['age', 'length_of_stay', 'diagnosis_count', 'medication_count']:\n",
    "    if col in master_df.columns:\n",
    "        numerical_features.append(col)\n",
    "\n",
    "print(f\"numerical features to normalize: {numerical_features}\")\n",
    "\n",
    "if len(numerical_features) > 0:\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # create normalized versions\n",
    "    for col in numerical_features:\n",
    "        master_df[f'{col}_normalized'] = scaler.fit_transform(master_df[[col]])\n",
    "        print(f\"  {col}_normalized created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd20e53",
   "metadata": {},
   "source": [
    "## 9. create temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b7ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          extracting temporal features                          \n",
      "================================================================================\n",
      "\n",
      "temporal features created:\n",
      "  - admission_year\n",
      "  - admission_month\n",
      "  - admission_day_of_week\n",
      "  - admission_quarter\n",
      "  - is_weekend_admission\n",
      "\n",
      "weekend admissions: 712 (28.70%)\n"
     ]
    }
   ],
   "source": [
    "# extract temporal features from dates\n",
    "print_section_header(\"extracting temporal features\")\n",
    "\n",
    "if 'admission_date' in master_df.columns:\n",
    "    master_df['admission_year'] = master_df['admission_date'].dt.year\n",
    "    master_df['admission_month'] = master_df['admission_date'].dt.month\n",
    "    master_df['admission_day_of_week'] = master_df['admission_date'].dt.dayofweek\n",
    "    master_df['admission_quarter'] = master_df['admission_date'].dt.quarter\n",
    "    \n",
    "    # weekend admission flag\n",
    "    master_df['is_weekend_admission'] = (master_df['admission_day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    print(\"temporal features created:\")\n",
    "    print(\"  - admission_year\")\n",
    "    print(\"  - admission_month\")\n",
    "    print(\"  - admission_day_of_week\")\n",
    "    print(\"  - admission_quarter\")\n",
    "    print(\"  - is_weekend_admission\")\n",
    "    \n",
    "    print(f\"\\nweekend admissions: {master_df['is_weekend_admission'].sum()} ({master_df['is_weekend_admission'].sum()/len(master_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23045e4",
   "metadata": {},
   "source": [
    "## 10. save transformed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98299da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 17:48:51,094 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\transformed_master_dataset.csv\n",
      "2025-11-10 17:48:51,128 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\encoded_dataset_for_ml.csv\n",
      "2025-11-10 17:48:51,144 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\ml_ready_features.csv\n",
      "2025-11-10 17:48:51,128 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\encoded_dataset_for_ml.csv\n",
      "2025-11-10 17:48:51,144 - root - INFO - saved dataframe to d:\\Github Desktop\\Python\\Hospital Data Curation\\data\\preprocessed\\ml_ready_features.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          saving transformed datasets                           \n",
      "================================================================================\n",
      "\n",
      "✓ transformed master dataset saved: 2481 rows, 36 columns\n",
      "✓ encoded dataset saved: 2481 rows, 40 columns\n",
      "✓ ml-ready features saved: 2481 rows, 8 columns\n"
     ]
    }
   ],
   "source": [
    "# save transformed datasets\n",
    "print_section_header(\"saving transformed datasets\")\n",
    "\n",
    "# save main transformed dataset\n",
    "save_dataframe(master_df, PREPROCESSED_DATA_DIR / 'transformed_master_dataset.csv')\n",
    "print(f\"✓ transformed master dataset saved: {len(master_df)} rows, {len(master_df.columns)} columns\")\n",
    "\n",
    "# save encoded dataset (for ML)\n",
    "save_dataframe(encoded_df, PREPROCESSED_DATA_DIR / 'encoded_dataset_for_ml.csv')\n",
    "print(f\"✓ encoded dataset saved: {len(encoded_df)} rows, {len(encoded_df.columns)} columns\")\n",
    "\n",
    "# create and save feature-ready dataset (only relevant features)\n",
    "ml_features = [col for col in master_df.columns if any(x in col for x in [\n",
    "    'age', 'length_of_stay', 'diagnosis_count', 'medication_count', \n",
    "    'is_readmitted', 'is_high_risk', '_normalized'\n",
    "])]\n",
    "\n",
    "# add target columns if they exist\n",
    "for target_col in ['is_readmitted', 'is_high_risk', 'length_of_stay']:\n",
    "    if target_col in master_df.columns and target_col not in ml_features:\n",
    "        ml_features.append(target_col)\n",
    "\n",
    "ml_ready_df = master_df[ml_features].copy()\n",
    "save_dataframe(ml_ready_df, PREPROCESSED_DATA_DIR / 'ml_ready_features.csv')\n",
    "print(f\"✓ ml-ready features saved: {len(ml_ready_df)} rows, {len(ml_ready_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff081ea",
   "metadata": {},
   "source": [
    "## 11. feature engineering summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5394d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                          feature engineering summary                           \n",
      "================================================================================\n",
      "\n",
      "engineered features:\n",
      "\n",
      "derived features:\n",
      "  ✓ length_of_stay\n",
      "  ✓ is_readmitted\n",
      "  ✓ days_since_last_admission\n",
      "  ✓ age_group\n",
      "  ✓ los_category\n",
      "  ✓ is_high_risk\n",
      "\n",
      "temporal features:\n",
      "  ✓ admission_year\n",
      "  ✓ admission_month\n",
      "  ✓ admission_day_of_week\n",
      "  ✓ admission_quarter\n",
      "  ✓ is_weekend_admission\n",
      "\n",
      "normalized features:\n",
      "  ✓ length_of_stay_normalized\n",
      "  ✓ diagnosis_count_normalized\n",
      "  ✓ medication_count_normalized\n",
      "\n",
      "one-hot encoded categories:\n",
      "  ✓ gender\n",
      "  ✓ los_category\n",
      "  ✓ admission_type\n",
      "\n",
      "total features in transformed dataset: 36\n",
      "total features in encoded dataset: 40\n",
      "ml-ready features: 8\n"
     ]
    }
   ],
   "source": [
    "# generate feature engineering summary\n",
    "print_section_header(\"feature engineering summary\")\n",
    "\n",
    "print(\"engineered features:\")\n",
    "print(\"\\nderived features:\")\n",
    "print(\"  ✓ length_of_stay\")\n",
    "print(\"  ✓ is_readmitted\")\n",
    "print(\"  ✓ days_since_last_admission\")\n",
    "print(\"  ✓ age_group\")\n",
    "print(\"  ✓ los_category\")\n",
    "print(\"  ✓ is_high_risk\")\n",
    "\n",
    "print(\"\\ntemporal features:\")\n",
    "print(\"  ✓ admission_year\")\n",
    "print(\"  ✓ admission_month\")\n",
    "print(\"  ✓ admission_day_of_week\")\n",
    "print(\"  ✓ admission_quarter\")\n",
    "print(\"  ✓ is_weekend_admission\")\n",
    "\n",
    "print(\"\\nnormalized features:\")\n",
    "for col in numerical_features:\n",
    "    print(f\"  ✓ {col}_normalized\")\n",
    "\n",
    "print(\"\\none-hot encoded categories:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"  ✓ {col}\")\n",
    "\n",
    "print(f\"\\ntotal features in transformed dataset: {len(master_df.columns)}\")\n",
    "print(f\"total features in encoded dataset: {len(encoded_df.columns)}\")\n",
    "print(f\"ml-ready features: {len(ml_ready_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1bc4a",
   "metadata": {},
   "source": [
    "## summary\n",
    "\n",
    "data transformation completed:\n",
    "- ✓ length of stay calculated\n",
    "- ✓ readmission flags generated\n",
    "- ✓ age groups and categories created\n",
    "- ✓ high-risk patient identification\n",
    "- ✓ categorical variables encoded\n",
    "- ✓ numerical features normalized\n",
    "- ✓ temporal features extracted\n",
    "- ✓ ml-ready datasets created\n",
    "\n",
    "next phase: data validation and quality assurance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
