{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7946178",
   "metadata": {},
   "source": [
    "# hospital data curation project\n",
    "## comprehensive project summary and handover document\n",
    "\n",
    "this notebook generates a complete summary of all data curation and analytics work performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39024821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# add src directory to python path\n",
    "notebook_dir = Path(os.getcwd())\n",
    "src_dir = notebook_dir / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import project modules\n",
    "import config\n",
    "import utils\n",
    "\n",
    "# use imported modules\n",
    "RAW_DATA_DIR = config.RAW_DATA_DIR\n",
    "CLEANED_DATA_DIR = config.CLEANED_DATA_DIR\n",
    "PREPROCESSED_DATA_DIR = config.PREPROCESSED_DATA_DIR\n",
    "LOGS_DIR = config.LOGS_DIR\n",
    "MODELS_DIR = config.MODELS_DIR\n",
    "VISUALIZATIONS_DIR = config.VISUALIZATIONS_DIR\n",
    "PROFILING_DIR = config.PROFILING_DIR\n",
    "SWEETVIZ_DIR = config.SWEETVIZ_DIR\n",
    "setup_logging = utils.setup_logging\n",
    "print_section_header = utils.print_section_header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52a4ee",
   "metadata": {},
   "source": [
    "## 1. project overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f5a717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    hospital data curation project - summary                    \n",
      "================================================================================\n",
      "\n",
      "project information:\n",
      "  project_name: hospital patient records cleanup and analytics\n",
      "  domain: healthcare\n",
      "  objective: clean, curate, and prepare hospital data for epidemiological research and predictive analytics\n",
      "  date_completed: 2025-11-10\n",
      "  total_phases: 9\n",
      "  compliance: hipaa-ready data handling\n"
     ]
    }
   ],
   "source": [
    "# project metadata\n",
    "print_section_header(\"hospital data curation project - summary\")\n",
    "\n",
    "project_info = {\n",
    "    'project_name': 'hospital patient records cleanup and analytics',\n",
    "    'domain': 'healthcare',\n",
    "    'objective': 'clean, curate, and prepare hospital data for epidemiological research and predictive analytics',\n",
    "    'date_completed': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'total_phases': 9,\n",
    "    'compliance': 'hipaa-ready data handling'\n",
    "}\n",
    "\n",
    "print(\"project information:\")\n",
    "for key, value in project_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba334967",
   "metadata": {},
   "source": [
    "## 2. datasets processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d38d798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                               datasets inventory                               \n",
      "================================================================================\n",
      "\n",
      "\n",
      "dataset inventory:\n",
      "        type                       filename  rows  columns    size_kb\n",
      "         raw                  diagnoses.csv  8000        4 352.329102\n",
      "         raw              hospital_info.csv    20        5   0.712891\n",
      "         raw                medications.csv  6000        6 323.243164\n",
      "         raw                   patients.csv  3000        7 366.284180\n",
      "         raw                      staff.csv   500        5  20.965820\n",
      "         raw                     visits.csv  5000        7 266.633789\n",
      "     cleaned            clean_diagnoses.csv  7998        5 391.287109\n",
      "     cleaned        clean_hospital_info.csv    20        5   0.712891\n",
      "     cleaned          clean_medications.csv  5324        6 286.842773\n",
      "     cleaned             clean_patients.csv  3000        7 375.029297\n",
      "     cleaned                clean_staff.csv   500        5  20.965820\n",
      "     cleaned               clean_visits.csv  2481        8 141.310547\n",
      "preprocessed          curated_diagnoses.csv  7998        5 391.287109\n",
      "preprocessed        curated_medications.csv  5324        6 286.842773\n",
      "preprocessed              curated_staff.csv   500        5  20.965820\n",
      "preprocessed     encoded_dataset_for_ml.csv  2481       40 843.008789\n",
      "preprocessed      master_patient_visits.csv  2481       24 626.294922\n",
      "preprocessed          ml_ready_features.csv  2481        8 183.853516\n",
      "preprocessed transformed_master_dataset.csv  2481       36 851.100586\n",
      "\n",
      "total datasets: 19\n",
      "total size: 5749.67 kb\n",
      "\n",
      "dataset inventory:\n",
      "        type                       filename  rows  columns    size_kb\n",
      "         raw                  diagnoses.csv  8000        4 352.329102\n",
      "         raw              hospital_info.csv    20        5   0.712891\n",
      "         raw                medications.csv  6000        6 323.243164\n",
      "         raw                   patients.csv  3000        7 366.284180\n",
      "         raw                      staff.csv   500        5  20.965820\n",
      "         raw                     visits.csv  5000        7 266.633789\n",
      "     cleaned            clean_diagnoses.csv  7998        5 391.287109\n",
      "     cleaned        clean_hospital_info.csv    20        5   0.712891\n",
      "     cleaned          clean_medications.csv  5324        6 286.842773\n",
      "     cleaned             clean_patients.csv  3000        7 375.029297\n",
      "     cleaned                clean_staff.csv   500        5  20.965820\n",
      "     cleaned               clean_visits.csv  2481        8 141.310547\n",
      "preprocessed          curated_diagnoses.csv  7998        5 391.287109\n",
      "preprocessed        curated_medications.csv  5324        6 286.842773\n",
      "preprocessed              curated_staff.csv   500        5  20.965820\n",
      "preprocessed     encoded_dataset_for_ml.csv  2481       40 843.008789\n",
      "preprocessed      master_patient_visits.csv  2481       24 626.294922\n",
      "preprocessed          ml_ready_features.csv  2481        8 183.853516\n",
      "preprocessed transformed_master_dataset.csv  2481       36 851.100586\n",
      "\n",
      "total datasets: 19\n",
      "total size: 5749.67 kb\n"
     ]
    }
   ],
   "source": [
    "# summarize all datasets\n",
    "print_section_header(\"datasets inventory\")\n",
    "\n",
    "datasets_summary = []\n",
    "\n",
    "# raw datasets\n",
    "for data_file in RAW_DATA_DIR.glob('*.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        datasets_summary.append({\n",
    "            'type': 'raw',\n",
    "            'filename': data_file.name,\n",
    "            'rows': len(df),\n",
    "            'columns': len(df.columns),\n",
    "            'size_kb': data_file.stat().st_size / 1024\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# cleaned datasets\n",
    "for data_file in CLEANED_DATA_DIR.glob('*.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        datasets_summary.append({\n",
    "            'type': 'cleaned',\n",
    "            'filename': data_file.name,\n",
    "            'rows': len(df),\n",
    "            'columns': len(df.columns),\n",
    "            'size_kb': data_file.stat().st_size / 1024\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# preprocessed datasets\n",
    "for data_file in PREPROCESSED_DATA_DIR.glob('*.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        datasets_summary.append({\n",
    "            'type': 'preprocessed',\n",
    "            'filename': data_file.name,\n",
    "            'rows': len(df),\n",
    "            'columns': len(df.columns),\n",
    "            'size_kb': data_file.stat().st_size / 1024\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if datasets_summary:\n",
    "    summary_df = pd.DataFrame(datasets_summary)\n",
    "    print(\"\\ndataset inventory:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\ntotal datasets: {len(summary_df)}\")\n",
    "    print(f\"total size: {summary_df['size_kb'].sum():.2f} kb\")\n",
    "else:\n",
    "    print(\"\\nno datasets found - ensure data files are in place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165bc42",
   "metadata": {},
   "source": [
    "## 3. data quality improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c649c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           data quality improvements                            \n",
      "================================================================================\n",
      "\n",
      "\n",
      "cleaning summary:\n",
      "    dataset  initial_rows  final_rows  removed_rows\n",
      "   patients          3000        3000             0\n",
      "     visits          5000        2481          2519\n",
      "  diagnoses          8000        7998             2\n",
      "medications          6000        5324           676\n",
      "      staff           500         500             0\n",
      "\n",
      "overall statistics:\n",
      "  total initial rows: 22500\n",
      "  total final rows: 19303\n",
      "  total removed rows: 3197 (14.21%)\n",
      "  data retention rate: 85.79%\n"
     ]
    }
   ],
   "source": [
    "# load cleaning report if available\n",
    "print_section_header(\"data quality improvements\")\n",
    "\n",
    "cleaning_report_file = LOGS_DIR / 'cleaning_report.csv'\n",
    "if cleaning_report_file.exists():\n",
    "    cleaning_df = pd.read_csv(cleaning_report_file)\n",
    "    print(\"\\ncleaning summary:\")\n",
    "    print(cleaning_df.to_string(index=False))\n",
    "    \n",
    "    total_initial = cleaning_df['initial_rows'].sum()\n",
    "    total_final = cleaning_df['final_rows'].sum()\n",
    "    total_removed = cleaning_df['removed_rows'].sum()\n",
    "    \n",
    "    print(f\"\\noverall statistics:\")\n",
    "    print(f\"  total initial rows: {total_initial}\")\n",
    "    print(f\"  total final rows: {total_final}\")\n",
    "    print(f\"  total removed rows: {total_removed} ({total_removed/total_initial*100:.2f}%)\")\n",
    "    print(f\"  data retention rate: {total_final/total_initial*100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\ncleaning report not found - run notebook 03_data_cleaning.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01b75b",
   "metadata": {},
   "source": [
    "## 4. validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1974bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            data validation results                             \n",
      "================================================================================\n",
      "\n",
      "\n",
      "quality scorecard:\n",
      "                   metric status details\n",
      "    patient id uniqueness ✓ pass    True\n",
      "      visit id uniqueness ✓ pass    True\n",
      "overall data completeness ✓ pass  96.19%\n",
      "         date consistency ✓ pass    True\n",
      "\n",
      "validation pass rate: 4/4 (100.0%)\n",
      "\n",
      "detailed validation report available at: d:\\Github Desktop\\Python\\Hospital Data Curation\\logs\\validation_report.txt\n"
     ]
    }
   ],
   "source": [
    "# load validation scorecard\n",
    "print_section_header(\"data validation results\")\n",
    "\n",
    "scorecard_file = LOGS_DIR / 'quality_scorecard.csv'\n",
    "if scorecard_file.exists():\n",
    "    scorecard_df = pd.read_csv(scorecard_file)\n",
    "    print(\"\\nquality scorecard:\")\n",
    "    print(scorecard_df.to_string(index=False))\n",
    "    \n",
    "    pass_count = scorecard_df['status'].str.contains('pass').sum()\n",
    "    total_checks = len(scorecard_df)\n",
    "    \n",
    "    print(f\"\\nvalidation pass rate: {pass_count}/{total_checks} ({pass_count/total_checks*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\nquality scorecard not found - run notebook 06_data_validation.ipynb\")\n",
    "\n",
    "# check for validation report\n",
    "validation_file = LOGS_DIR / 'validation_report.txt'\n",
    "if validation_file.exists():\n",
    "    print(f\"\\ndetailed validation report available at: {validation_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e42f4f",
   "metadata": {},
   "source": [
    "## 5. machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b01d5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            machine learning models                             \n",
      "================================================================================\n",
      "\n",
      "\n",
      "regression analysis (length of stay prediction):\n",
      "            model  train_rmse  test_rmse  train_mae  test_mae  train_r2   test_r2\n",
      "linear regression  104.530297 105.974927  90.292414 92.027624  0.005783 -0.001454\n",
      " ridge regression  104.530298 105.974981  90.292471 92.027865  0.005783 -0.001456\n",
      " lasso regression  104.530545 105.960289  90.297439 92.024668  0.005778 -0.001178\n",
      "\n",
      "best model: lasso regression (rmse: 105.960 days)\n",
      "\n",
      "\n",
      "classification analysis (readmission prediction):\n",
      "            model  accuracy  precision  recall  f1_score  auc_roc\n",
      "    decision tree  0.953722        0.0     0.0       0.0 0.605944\n",
      "    random forest  0.953722        0.0     0.0       0.0 0.602825\n",
      "gradient boosting  0.943662        0.0     0.0       0.0 0.492845\n",
      "\n",
      "best model: decision tree (f1-score: 0.000)\n",
      "\n",
      "\n",
      "trained model files: 8\n",
      "  - decision_tree_readmission.pkl\n",
      "  - gradient_boosting_readmission.pkl\n",
      "  - lasso_regression_los.pkl\n",
      "  - linear_regression_los.pkl\n",
      "  - los_feature_scaler.pkl\n",
      "  - random_forest_readmission.pkl\n",
      "  - readmission_feature_scaler.pkl\n",
      "  - ridge_regression_los.pkl\n"
     ]
    }
   ],
   "source": [
    "# summarize trained models\n",
    "print_section_header(\"machine learning models\")\n",
    "\n",
    "# regression models\n",
    "regression_comparison_file = MODELS_DIR / 'regression_model_comparison.csv'\n",
    "if regression_comparison_file.exists():\n",
    "    print(\"\\nregression analysis (length of stay prediction):\")\n",
    "    regression_df = pd.read_csv(regression_comparison_file)\n",
    "    print(regression_df.to_string(index=False))\n",
    "    \n",
    "    best_model = regression_df.loc[regression_df['test_rmse'].idxmin(), 'model']\n",
    "    best_rmse = regression_df['test_rmse'].min()\n",
    "    print(f\"\\nbest model: {best_model} (rmse: {best_rmse:.3f} days)\")\n",
    "\n",
    "# classification models\n",
    "classification_comparison_file = MODELS_DIR / 'classification_model_comparison.csv'\n",
    "if classification_comparison_file.exists():\n",
    "    print(\"\\n\\nclassification analysis (readmission prediction):\")\n",
    "    classification_df = pd.read_csv(classification_comparison_file)\n",
    "    print(classification_df.to_string(index=False))\n",
    "    \n",
    "    best_model = classification_df.loc[classification_df['f1_score'].idxmax(), 'model']\n",
    "    best_f1 = classification_df['f1_score'].max()\n",
    "    print(f\"\\nbest model: {best_model} (f1-score: {best_f1:.3f})\")\n",
    "\n",
    "# count model files\n",
    "model_files = list(MODELS_DIR.glob('*.pkl'))\n",
    "print(f\"\\n\\ntrained model files: {len(model_files)}\")\n",
    "for model_file in model_files:\n",
    "    print(f\"  - {model_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf7c1d",
   "metadata": {},
   "source": [
    "## 6. association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bbf64d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        association rule mining results                         \n",
      "================================================================================\n",
      "\n",
      "\n",
      "diagnosis co-occurrence patterns:\n",
      "  total rules: 0\n",
      "\n",
      "medication prescription patterns:\n",
      "  total rules: 20\n",
      "  avg confidence: 0.216\n",
      "  avg lift: 0.706\n",
      "  top rule confidence: 0.235\n",
      "\n",
      "diagnosis → medication associations:\n",
      "  total rules: 0\n",
      "\n",
      "readmission risk rules:\n",
      "  total rules: 0\n"
     ]
    }
   ],
   "source": [
    "# summarize association rules\n",
    "print_section_header(\"association rule mining results\")\n",
    "\n",
    "rule_files = {\n",
    "    'diagnosis_association_rules.csv': 'diagnosis co-occurrence patterns',\n",
    "    'medication_association_rules.csv': 'medication prescription patterns',\n",
    "    'combined_association_rules.csv': 'diagnosis → medication associations',\n",
    "    'readmission_prediction_rules.csv': 'readmission risk rules'\n",
    "}\n",
    "\n",
    "for filename, description in rule_files.items():\n",
    "    rule_file = MODELS_DIR / filename\n",
    "    if rule_file.exists():\n",
    "        rules_df = pd.read_csv(rule_file)\n",
    "        print(f\"\\n{description}:\")\n",
    "        print(f\"  total rules: {len(rules_df)}\")\n",
    "        if len(rules_df) > 0:\n",
    "            print(f\"  avg confidence: {rules_df['confidence'].mean():.3f}\")\n",
    "            print(f\"  avg lift: {rules_df['lift'].mean():.3f}\")\n",
    "            print(f\"  top rule confidence: {rules_df['confidence'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f282de",
   "metadata": {},
   "source": [
    "## 7. reports and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9c6e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                      generated reports and visualizations                      \n",
      "================================================================================\n",
      "\n",
      "\n",
      "ydata profiling reports: 6\n",
      "  - diagnoses_profile_20251110_174348.html\n",
      "  - hospital_info_profile_20251110_174348.html\n",
      "  - medications_profile_20251110_174348.html\n",
      "  - patients_profile_20251110_174348.html\n",
      "  - staff_profile_20251110_174348.html\n",
      "  - visits_profile_20251110_174348.html\n",
      "\n",
      "sweetviz reports: 6\n",
      "  - diagnoses_sweetviz_20251110_174348.html\n",
      "  - hospital_info_sweetviz_20251110_174348.html\n",
      "  - medications_sweetviz_20251110_174348.html\n",
      "  - patients_sweetviz_20251110_174348.html\n",
      "  - staff_sweetviz_20251110_174348.html\n",
      "  - visits_sweetviz_20251110_174348.html\n",
      "\n",
      "visualizations: 8\n",
      "  - association_lift_distribution.png\n",
      "  - classification_confusion_matrices.png\n",
      "  - classification_feature_importance.png\n",
      "  - classification_roc_curves.png\n",
      "  - regression_actual_vs_predicted.png\n",
      "  - regression_model_comparison.png\n",
      "  - regression_residuals.png\n",
      "  - top_medications_frequency.png\n",
      "\n",
      "log and report files: 7\n",
      "  - cleaning_report.csv\n",
      "  - completeness_report.csv\n",
      "  - data_dictionary.csv\n",
      "  - initial_quality_report.csv\n",
      "  - metadata_report.csv\n",
      "  - quality_scorecard.csv\n",
      "  - validation_report.txt\n"
     ]
    }
   ],
   "source": [
    "# inventory reports and visualizations\n",
    "print_section_header(\"generated reports and visualizations\")\n",
    "\n",
    "# profiling reports\n",
    "profiling_reports = list(PROFILING_DIR.glob('*.html'))\n",
    "print(f\"\\nydata profiling reports: {len(profiling_reports)}\")\n",
    "for report in profiling_reports:\n",
    "    print(f\"  - {report.name}\")\n",
    "\n",
    "# sweetviz reports\n",
    "sweetviz_reports = list(SWEETVIZ_DIR.glob('*.html'))\n",
    "print(f\"\\nsweetviz reports: {len(sweetviz_reports)}\")\n",
    "for report in sweetviz_reports:\n",
    "    print(f\"  - {report.name}\")\n",
    "\n",
    "# visualizations\n",
    "viz_files = list(VISUALIZATIONS_DIR.glob('*.png'))\n",
    "print(f\"\\nvisualizations: {len(viz_files)}\")\n",
    "for viz_file in viz_files:\n",
    "    print(f\"  - {viz_file.name}\")\n",
    "\n",
    "# log files\n",
    "log_files = list(LOGS_DIR.glob('*.csv')) + list(LOGS_DIR.glob('*.txt'))\n",
    "print(f\"\\nlog and report files: {len(log_files)}\")\n",
    "for log_file in log_files:\n",
    "    print(f\"  - {log_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb56cf",
   "metadata": {},
   "source": [
    "## 8. key performance indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e4c9f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           key performance indicators                           \n",
      "================================================================================\n",
      "\n",
      "\n",
      "key performance indicators:\n",
      "  average_length_of_stay: 182.27 days\n",
      "  median_length_of_stay: 180.00 days\n",
      "  readmission_rate: 4.72%\n",
      "  high_risk_patient_rate: 21.93%\n",
      "  unique_patients: 1692\n",
      "  total_visits: 2481\n",
      "  avg_diagnoses_per_visit: 1.63\n",
      "  avg_medications_per_visit: 1.06\n"
     ]
    }
   ],
   "source": [
    "# calculate key metrics from master dataset\n",
    "print_section_header(\"key performance indicators\")\n",
    "\n",
    "master_file = PREPROCESSED_DATA_DIR / 'transformed_master_dataset.csv'\n",
    "if master_file.exists():\n",
    "    master_df = pd.read_csv(master_file)\n",
    "    \n",
    "    kpis = {}\n",
    "    \n",
    "    # length of stay\n",
    "    if 'length_of_stay' in master_df.columns:\n",
    "        kpis['average_length_of_stay'] = f\"{master_df['length_of_stay'].mean():.2f} days\"\n",
    "        kpis['median_length_of_stay'] = f\"{master_df['length_of_stay'].median():.2f} days\"\n",
    "    \n",
    "    # readmission rate\n",
    "    if 'is_readmitted' in master_df.columns:\n",
    "        readmission_rate = (master_df['is_readmitted'].sum() / len(master_df)) * 100\n",
    "        kpis['readmission_rate'] = f\"{readmission_rate:.2f}%\"\n",
    "    \n",
    "    # high-risk patients\n",
    "    if 'is_high_risk' in master_df.columns:\n",
    "        high_risk_rate = (master_df['is_high_risk'].sum() / len(master_df)) * 100\n",
    "        kpis['high_risk_patient_rate'] = f\"{high_risk_rate:.2f}%\"\n",
    "    \n",
    "    # unique patients and visits\n",
    "    if 'patient_id' in master_df.columns:\n",
    "        kpis['unique_patients'] = master_df['patient_id'].nunique()\n",
    "    if 'visit_id' in master_df.columns:\n",
    "        kpis['total_visits'] = master_df['visit_id'].nunique()\n",
    "    \n",
    "    # average diagnoses and medications\n",
    "    if 'diagnosis_count' in master_df.columns:\n",
    "        kpis['avg_diagnoses_per_visit'] = f\"{master_df['diagnosis_count'].mean():.2f}\"\n",
    "    if 'medication_count' in master_df.columns:\n",
    "        kpis['avg_medications_per_visit'] = f\"{master_df['medication_count'].mean():.2f}\"\n",
    "    \n",
    "    print(\"\\nkey performance indicators:\")\n",
    "    for metric, value in kpis.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "else:\n",
    "    print(\"\\nmaster dataset not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237394d",
   "metadata": {},
   "source": [
    "## 9. project deliverables checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbfd0aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         project deliverables checklist                         \n",
      "================================================================================\n",
      "\n",
      "\n",
      "deliverables status:\n",
      "  ✓ cleaned datasets: 6 file(s)\n",
      "  ✓ integrated datasets: 7 file(s)\n",
      "  ✓ profiling reports: 6 file(s)\n",
      "  ✓ sweetviz reports: 6 file(s)\n",
      "  ✓ validation reports: 2 file(s)\n",
      "  ✓ data dictionary: 2 file(s)\n",
      "  ✓ ml models: 8 file(s)\n",
      "  ✓ association rules: 4 file(s)\n",
      "  ✓ visualizations: 8 file(s)\n",
      "  ✓ documentation: 1 file(s)\n",
      "\n",
      "                         project deliverables checklist                         \n",
      "================================================================================\n",
      "\n",
      "\n",
      "deliverables status:\n",
      "  ✓ cleaned datasets: 6 file(s)\n",
      "  ✓ integrated datasets: 7 file(s)\n",
      "  ✓ profiling reports: 6 file(s)\n",
      "  ✓ sweetviz reports: 6 file(s)\n",
      "  ✓ validation reports: 2 file(s)\n",
      "  ✓ data dictionary: 2 file(s)\n",
      "  ✓ ml models: 8 file(s)\n",
      "  ✓ association rules: 4 file(s)\n",
      "  ✓ visualizations: 8 file(s)\n",
      "  ✓ documentation: 1 file(s)\n"
     ]
    }
   ],
   "source": [
    "# create deliverables checklist\n",
    "print_section_header(\"project deliverables checklist\")\n",
    "\n",
    "deliverables = [\n",
    "    ('cleaned datasets', CLEANED_DATA_DIR, '*.csv'),\n",
    "    ('integrated datasets', PREPROCESSED_DATA_DIR, '*.csv'),\n",
    "    ('profiling reports', PROFILING_DIR, '*.html'),\n",
    "    ('sweetviz reports', SWEETVIZ_DIR, '*.html'),\n",
    "    ('validation reports', LOGS_DIR, ['validation_report.txt', 'quality_scorecard.csv']),\n",
    "    ('data dictionary', LOGS_DIR, ['data_dictionary.csv', 'data_dictionary.xlsx']),\n",
    "    ('ml models', MODELS_DIR, '*.pkl'),\n",
    "    ('association rules', MODELS_DIR, '*_rules.csv'),\n",
    "    ('visualizations', VISUALIZATIONS_DIR, '*.png'),\n",
    "    ('documentation', Path('.'), 'README.md')\n",
    "]\n",
    "\n",
    "print(\"\\ndeliverables status:\")\n",
    "for deliverable_name, directory, pattern in deliverables:\n",
    "    if isinstance(pattern, list):\n",
    "        files = [directory / p for p in pattern]\n",
    "        exists = all(f.exists() for f in files)\n",
    "        count = len([f for f in files if f.exists()])\n",
    "    else:\n",
    "        files = list(directory.glob(pattern))\n",
    "        exists = len(files) > 0\n",
    "        count = len(files)\n",
    "    \n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {deliverable_name}: {count} file(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42450a2",
   "metadata": {},
   "source": [
    "## summary\n",
    "\n",
    "comprehensive project summary completed:\n",
    "- ✓ all datasets inventoried\n",
    "- ✓ quality improvements documented\n",
    "- ✓ validation results summarized\n",
    "- ✓ ml models catalogued\n",
    "- ✓ reports and visualizations listed\n",
    "- ✓ kpis calculated\n",
    "- ✓ deliverables checklist verified\n",
    "- ✓ handover document generated\n",
    "\n",
    "**project successfully completed and documented!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
